{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LRP.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO8b9zVuBbPcP+VjVRFhe8C"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wXXN1MGv8t0J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613369177315,"user_tz":-540,"elapsed":19882,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"5c0f565a-fa2f-476b-cf9d-76e411afc69e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rUI8Ukot8l0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613369187855,"user_tz":-540,"elapsed":3136,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"434258e4-4da4-463b-ca92-14ed01716f70"},"source":["import re\n","import nltk\n","import operator\n","import numpy as np\n","import pandas as pd\n","from math import log\n","import urllib.request\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from nltk.corpus import stopwords\n","from sklearn.preprocessing import LabelEncoder\n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"QZhJvjeFifW1"},"source":["# amazon = pd.read_csv('/content/drive/My Drive/amazon_reviews.csv')\r\n","binary_airline = pd.read_csv('/content/drive/My Drive/binary_air_review.csv')\r\n","# binary_hotel = pd.read_csv('/content/drive/My Drive/hotel-reviews.csv')\r\n","# clothing = pd.read_csv('/content/drive/My Drive/clothing.csv')\r\n","# movie = pd.read_csv('/content/drive/My Drive/train.csv')\r\n","# steam = pd.read_csv('/content/drive/My Drive/steam.csv')\r\n","# yelp = pd.read_csv('/content/drive/My Drive/yelp.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N8dWDdR1fIQf"},"source":["# sorting = amazon.sort_values(['label'])                     ## contents\r\n","sorting = binary_airline.sort_values(['rating'])            ## comment\r\n","# sorting = binary_hotel.sort_values(['Is_Response'])         ## Description\r\n","# sorting = clothing.sort_values(['Recommended IND'])         ## Review Text\r\n","# sorting = movie.sort_values(['sentiment'])                  ## text\r\n","# sorting = steam.sort_values(['user_suggestion'])            ## user_review\r\n","# sorting = yelp.sort_values(['rating'])                      ## review"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"FErmQtLKebkO","executionInfo":{"status":"ok","timestamp":1614767620315,"user_tz":-540,"elapsed":3649,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"01566901-da58-418e-d5b0-fdd07df1e14b"},"source":["sorting"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>comment</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Good customer service thejith. Dealing with cu...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24897</th>\n","      <td>24897</td>\n","      <td>I have used WallyPark several times with very ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24898</th>\n","      <td>24898</td>\n","      <td>Very happy and pleased with experience at Wall...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24899</th>\n","      <td>24899</td>\n","      <td>Will not park anywhere else! Quality of servic...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24900</th>\n","      <td>24900</td>\n","      <td>Quality and service has fallen off, plus ended...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49776</th>\n","      <td>103536</td>\n","      <td>This was our first and last experience with Wa...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>49777</th>\n","      <td>103537</td>\n","      <td>Had some really bad experiences: 1) Was LIED t...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>49778</th>\n","      <td>103538</td>\n","      <td>Excellent service and excellent products! When...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>49798</th>\n","      <td>103558</td>\n","      <td>Booked 3 rooms and was sent a misleading email...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>74622</th>\n","      <td>128382</td>\n","      <td>After flight cancellation I was told that they...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>74623 rows × 3 columns</p>\n","</div>"],"text/plain":["       Unnamed: 0                                            comment  rating\n","0               0  Good customer service thejith. Dealing with cu...       0\n","24897       24897  I have used WallyPark several times with very ...       0\n","24898       24898  Very happy and pleased with experience at Wall...       0\n","24899       24899  Will not park anywhere else! Quality of servic...       0\n","24900       24900  Quality and service has fallen off, plus ended...       0\n","...           ...                                                ...     ...\n","49776      103536  This was our first and last experience with Wa...       1\n","49777      103537  Had some really bad experiences: 1) Was LIED t...       1\n","49778      103538  Excellent service and excellent products! When...       1\n","49798      103558  Booked 3 rooms and was sent a misleading email...       1\n","74622      128382  After flight cancellation I was told that they...       1\n","\n","[74623 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"zMXLZmdBb9Es"},"source":["## 본문부분 열 이름과 점수부분 열 이름 입력\r\n","\r\n","contents_name = \"comment\"\r\n","label_name = \"rating\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"opkn4pfYRI_P"},"source":["def data_loading(sorting, contents_name, label_name):\r\n","\r\n","  review_ = sorting.reset_index()\r\n","  # 라벨 인코더 생성\r\n","  encoder = LabelEncoder()\r\n","\r\n","  # X_train데이터를 이용 피팅하고 라벨숫자로 변환한다\r\n","  encoder.fit(review_[label_name])\r\n","  target_encoded = encoder.transform(review_[label_name])\r\n","\r\n","  contents = list(np.array(review_[contents_name].tolist()))\r\n","  label = list(target_encoded)\r\n","  cnts_N = contents[:2000]+contents[-2000:]   ## X_train\r\n","  label_N = label[:2000]+label[-2000:]        ## y_train\r\n","\r\n","  ## train data를 제외한 test data\r\n","  test_dict = {'document':contents[2000:-2000],\"label\":label[2000:-2000]}\r\n","  test_df = pd.DataFrame(test_dict)\r\n","\r\n","  np.random.seed(0)\r\n","\r\n","  df_shuffled=test_df.iloc[np.random.permutation(test_df.index)].reset_index(drop=True)\r\n","  df_shuffled\r\n","\r\n","  tdata = df_shuffled['document']\r\n","  tlabel = df_shuffled['label']\r\n","\r\n","  return cnts_N, label_N, tdata, tlabel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JACMV7qsbwsM"},"source":["## train test split과 같이 진행\r\n","\r\n","train_X, train_Y, test_X, test_Y = data_loading(sorting, contents_name, label_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nEbM6avmKacU"},"source":["def preprocessing(data):\r\n","\r\n","    from nltk import FreqDist\r\n","    from nltk.stem.snowball import SnowballStemmer\r\n","    snowball = SnowballStemmer('english')\r\n","\r\n","    normalized_text = []  ## 괄호 제거 및 문자이외의 데이터 제거\r\n","    for scr in data:\r\n","        scr = re.sub('\\(', ' ', scr)\r\n","        scr = re.sub('\\)', ' ', scr)\r\n","        scr = re.sub('[^ a-zA-Zㄱ-힗]', '', scr)\r\n","        normalized_text.append(scr.lower())\r\n","\r\n","    result = [word_tokenize(sentence) for sentence in normalized_text]  ## 토큰화\r\n","\r\n","    ## 단어 빈도 수 계산( 10번이상 등장하지 않는 단어 stopword에 포함 )\r\n","    vocab = list(set(w for i in result for w in i))\r\n","    vocab.sort()\r\n","\r\n","    check_freq = []\r\n","    for line in result:\r\n","        for wd in line:\r\n","            check_freq.append(wd)\r\n","\r\n","    fdist = FreqDist(check_freq)\r\n","\r\n","    low_freq = []\r\n","    for i in vocab:\r\n","        if fdist[i] < 10:\r\n","            low_freq.append(i)\r\n","\r\n","    stop_words = set(stopwords.words('english'))\r\n","    stop_words = list(stop_words)\r\n","    for i in low_freq:\r\n","        stop_words.append(i)\r\n","\r\n","    ## stopwords 제거 및 stemming\r\n","    except_stopword = []\r\n","    for st in result:\r\n","        temp = []\r\n","        for tk in st:\r\n","            if tk not in stop_words:\r\n","                temp.append(snowball.stem(tk))\r\n","        except_stopword.append(temp)\r\n","    \r\n","    return except_stopword"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_FFzz4URDGI"},"source":["train_tokens = preprocessing(train_X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6niA2rtby9nv","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"ok","timestamp":1612852726984,"user_tz":-540,"elapsed":140350,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"b7aed94e-544c-4c3e-be4a-e91c9c558725"},"source":["print('리뷰의 최대 길이 :',max(len(l) for l in train_tokens))\n","print('리뷰의 평균 길이 :',sum(map(len, train_tokens))/len(train_tokens))\n","plt.hist([len(s) for s in train_tokens], bins=50)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["리뷰의 최대 길이 : 606\n","리뷰의 평균 길이 : 71.26575\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"NPer_02my9nv"},"source":["vocabs = list(set(w for i in train_tokens for w in i ))\n","vocabs.sort()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"JyKIKzAHy9nv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612852727382,"user_tz":-540,"elapsed":140400,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"70e92daa-13b3-4fc9-ab9d-5cbcc03f39c2"},"source":["print('단어의 갯수는 총 %d개 이다'%(len(vocab)))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2301"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"7JbAIJSIrIdL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612852727383,"user_tz":-540,"elapsed":140269,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"20f9eee9-7057-49f4-ba0c-caba3f425bc8"},"source":["def corpus(tokens):\n","  corp = []\n","  for sent in tokens:\n","    tmp = \" \".join(sent)\n","    corp.append(tmp)\n","\n","  return corp\n","\n","train_corp = corpus(train_tokens)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['westin wonder hotel bed linen excel pay internet',\n"," 'excel hotel excel servic book superior king room upon check offer suit tower th floor free internet seper live area night turn main sister across street suit rd floor marriott overlook time squar higher floor told man check us happi play along assign room th floor room huge cours floor ceil window nice view river could even see empir state build behind sea okay suit sweet room larg flat tv coffe maker window would open decor beauti bit noisi could hear almost everyth hallway much one problem busi center printer work husband print someth concierg direct us nearbi abl use comput print got great deal night ever back nyc certain tri get deal excel hotel',\n"," 'travel lot usual month year us middl east say order put staff lenox welcom continu help time room alway clean whole environ warm tradit nice mix modern free internet ipod station hd tvs make satisfactori locat superb major sight within walk distanc street prudenti copley squar right definit stay next visit boston honest say dollar dollar one best hotel ever stay']"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"Y31Wb1sZ_0c9"},"source":["Word Embedding"]},{"cell_type":"code","metadata":{"id":"mGpPnhXqzeyY"},"source":["from gensim.models import Word2Vec\n","max_len = int(sum(map(len, train_tokens))/len(train_tokens))\n","w2v_model = Word2Vec(sentences = train_tokens, size = 1)\n","w2v_matrix = w2v_model.wv.vectors"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CgmuGOYhzetU"},"source":["index2word = {i+2: w for i, w in enumerate(w2v_model.wv.index2word)} \n","index2word[0] = 'PAD'\n","index2word[1] = 'UNK'\n","word2index = {w: i for i, w in index2word.items() }\n","vocab_size = len(vocabs) + 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5LOKRtChAI-F"},"source":["행렬 생성"]},{"cell_type":"code","metadata":{"id":"Z4wdFzd1zeqk"},"source":["from keras.preprocessing import sequence\n","\n","num_recs = len(train_tokens)\n","\n","X = np.empty((num_recs, ), dtype=list)     \n","y = np.zeros((num_recs, ))\n","i = 0\n","\n","for sentence, label in zip(train_corp, train_Y):\n","    words = nltk.word_tokenize(sentence)  \n","    seqs = []\n","    for word in words:                 \n","        if word in word2index:         \n","            seqs.append(word2index[word])       \n","        else:\n","            seqs.append(word2index[\"UNK\"])   \n","\n","    X[i] = seqs              \n","    y[i] = int(label)        \n","    i += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VrDzpWpVzenx"},"source":["X_train = sequence.pad_sequences(X, maxlen=max_len)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ovpnBnv5zekz"},"source":["y_train = np.array(train_Y)\n","y_train = y_train.reshape(-1,1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cASjCiv3v_DW"},"source":["X_test = preprocessing(test_X[:1000])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4jsMl0H4wz6W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612852746160,"user_tz":-540,"elapsed":157456,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"b70dc71d-e54b-482a-e041-f8192e754733"},"source":["new = np.empty((len(X_test), ), dtype= list)   # (1, ~) 벡터 만들기\n","\n","for i, words in enumerate(X_test):\n","  seq = []\n","  for word in words:\n","    if word in word2index:\n","      seq.append(word2index[word])\n","    else:\n","      seq.append(word2index[\"UNK\"])\n","  new[i] = seq\n","\n","new_input = sequence.pad_sequences(new, maxlen=max_len)\n","new_input.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1000, 71)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"HE8ZNvrZxoSt"},"source":["y_test = np.array(test_Y[:1000])\n","y_test = y_test.reshape(-1,1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZnLQFicerzPa"},"source":["# start LRP"]},{"cell_type":"code","metadata":{"id":"UxwrkDQxr1sC"},"source":["from __future__ import print_function\n","import numpy as np\n","import keras\n","\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n","\n","\n","from keras.models import Model, load_model\n","\n","import matplotlib.pyplot as plt\n","from IPython.display import display, HTML\n","\n","from numpy import newaxis as na"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WXF7VDo_r6Kp"},"source":["max_features = 10000\n","batch_size = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DO78BBVJr8ag"},"source":["num_classes = 2\n","\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_SBcwMI_r8Pu"},"source":["model = Sequential()\n","model.add(Embedding(max_features, 128))\n","model.add(LSTM(64))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='sigmoid'))\n","\n","model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x2yIpkzGMcu_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612852817054,"user_tz":-540,"elapsed":227466,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"1a5f609e-1d4f-455f-da12-828dfb424d57"},"source":["print('Train...')\n","model.fit(X_train, y_train,\n","          batch_size=batch_size,\n","          epochs=10,\n","          validation_split = 0.2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train...\n","Epoch 1/10\n","100/100 [==============================] - 10s 78ms/step - loss: 0.6400 - accuracy: 0.6299 - val_loss: 0.5638 - val_accuracy: 0.7925\n","Epoch 2/10\n","100/100 [==============================] - 7s 69ms/step - loss: 0.3258 - accuracy: 0.8780 - val_loss: 0.4945 - val_accuracy: 0.7825\n","Epoch 3/10\n","100/100 [==============================] - 7s 69ms/step - loss: 0.2425 - accuracy: 0.9281 - val_loss: 0.7154 - val_accuracy: 0.7513\n","Epoch 4/10\n","100/100 [==============================] - 7s 68ms/step - loss: 0.1850 - accuracy: 0.9474 - val_loss: 0.6038 - val_accuracy: 0.8112\n","Epoch 5/10\n","100/100 [==============================] - 7s 66ms/step - loss: 0.1166 - accuracy: 0.9705 - val_loss: 0.8351 - val_accuracy: 0.7362\n","Epoch 6/10\n","100/100 [==============================] - 7s 69ms/step - loss: 0.1144 - accuracy: 0.9708 - val_loss: 0.8946 - val_accuracy: 0.7400\n","Epoch 7/10\n","100/100 [==============================] - 7s 68ms/step - loss: 0.0828 - accuracy: 0.9776 - val_loss: 0.6257 - val_accuracy: 0.8325\n","Epoch 8/10\n","100/100 [==============================] - 7s 68ms/step - loss: 0.1038 - accuracy: 0.9698 - val_loss: 0.6084 - val_accuracy: 0.8213\n","Epoch 9/10\n","100/100 [==============================] - 7s 69ms/step - loss: 0.0651 - accuracy: 0.9816 - val_loss: 0.7547 - val_accuracy: 0.7862\n","Epoch 10/10\n","100/100 [==============================] - 6s 61ms/step - loss: 0.0627 - accuracy: 0.9853 - val_loss: 0.9646 - val_accuracy: 0.7550\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fe0c643a208>"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"0Yjq8hK7sMOS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612852817055,"user_tz":-540,"elapsed":227344,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"fbacc25a-8c9a-4f19-d98a-b68daed5dc78"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 128)         1280000   \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 64)                49408     \n","_________________________________________________________________\n","dropout (Dropout)            (None, 64)                0         \n","_________________________________________________________________\n","dense (Dense)                (None, 2)                 130       \n","=================================================================\n","Total params: 1,329,538\n","Trainable params: 1,329,538\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kLQtwaVDM0sg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612852817857,"user_tz":-540,"elapsed":228024,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"6fd27baf-9d5a-4c05-9b93-3ae25f7ca102"},"source":["results = model.evaluate(new_input, y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["32/32 [==============================] - 1s 12ms/step - loss: 0.6527 - accuracy: 0.8160\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tA703VQdsSAf"},"source":["model.save('lstm.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aj_tDVa3sTrz"},"source":["def html_heatmap (words, scores, cmap_name=\"bwr\"):\n","    \"\"\"\n","    Return word-level heatmap in HTML format,\n","    with words being the list of words (as string),\n","    scores the corresponding list of word-level relevance values,\n","    and cmap_name the name of the matplotlib diverging colormap.\n","    \"\"\"\n","    \n","    colormap  = plt.get_cmap(cmap_name)\n","     \n","    #assert len(words)==len(scores)\n","    max_s     = max(scores)\n","    min_s     = min(scores)\n","    \n","    output_text = \"\"\n","    \n","    for idx, w in enumerate(words):\n","        score       = rescale_score_by_abs(scores[idx], max_s, min_s)\n","        output_text = output_text + span_word(w, score, colormap) + \" \"\n","    \n","    return output_text + \"\\n\"\n","\n","def rescale_score_by_abs (score, max_score, min_score):\n","    \"\"\"\n","    Normalize the relevance value (=score), accordingly to the extremal relevance values (max_score and min_score), \n","    for visualization with a diverging colormap.\n","    i.e. rescale positive relevance to the range [0.5, 1.0], and negative relevance to the range [0.0, 0.5],\n","    using the highest absolute relevance for linear interpolation.\n","    \"\"\"\n","    \n","    # CASE 1: positive AND negative scores occur --------------------\n","    if max_score>0 and min_score<0:\n","    \n","        if max_score >= abs(min_score):   # deepest color is positive\n","            if score>=0:\n","                return 0.5 + 0.5*(score/max_score)\n","            else:\n","                return 0.5 - 0.5*(abs(score)/max_score)\n","\n","        else:                             # deepest color is negative\n","            if score>=0:\n","                return 0.5 + 0.5*(score/abs(min_score))\n","            else:\n","                return 0.5 - 0.5*(score/min_score)   \n","    \n","    # CASE 2: ONLY positive scores occur -----------------------------       \n","    elif max_score>0 and min_score>=0: \n","        if max_score == min_score:\n","            return 1.0\n","        else:\n","            return 0.5 + 0.5*(score/max_score)\n","    \n","    # CASE 3: ONLY negative scores occur -----------------------------\n","    elif max_score<=0 and min_score<0: \n","        if max_score == min_score:\n","            return 0.0\n","        else:\n","            return 0.5 - 0.5*(score/min_score)\n","          \n","\n","def getRGB (c_tuple):\n","    return \"#%02x%02x%02x\"%(int(c_tuple[0]*255), int(c_tuple[1]*255), int(c_tuple[2]*255))\n","\n","     \n","def span_word (word, score, colormap):\n","    return \"<span style=\\\"background-color:\"+getRGB(colormap(score))+\"\\\">\"+word+\"</span>\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2WxMg-6tgI8"},"source":["def get_layer_output(layer_name, data):\n","    # https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer\n","    intermediate_layer_model = keras.Model(inputs=model.input,\n","                                     outputs=model.get_layer(layer_name).output)\n","    return intermediate_layer_model.predict(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OiIVsNtTtiED"},"source":["names = [weight.name for layer in model.layers for weight in layer.weights]\n","weights = model.get_weights()\n","\n","# suppress scientific notation\n","np.set_printoptions(suppress=True)\n","for name, weight in zip(names, weights):\n","    if name == 'lstm/lstm_cell/kernel:0':\n","        kernel_0 = weight\n","    if name == 'lstm/lstm_cell/recurrent_kernel:0':\n","        recurrent_kernel_0 = weight\n","    if name == 'lstm/lstm_cell/bias:0':\n","        bias_0 = weight\n","    elif name == 'dense/kernel:0':\n","        output = weight"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHb2kX0huPvJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612852818307,"user_tz":-540,"elapsed":227552,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"5fb26609-ef51-4b53-bc06-e4b464b3e6ff"},"source":["names"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['embedding/embeddings:0',\n"," 'lstm/lstm_cell/kernel:0',\n"," 'lstm/lstm_cell/recurrent_kernel:0',\n"," 'lstm/lstm_cell/bias:0',\n"," 'dense/kernel:0',\n"," 'dense/bias:0']"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"P2V1A5LTtuLT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612852818308,"user_tz":-540,"elapsed":227413,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"6d989ee2-5986-4492-addb-cbb81af59b0f"},"source":["print(\"kernel_0\", kernel_0.shape)\n","print(\"recurrent_kernel_0\", recurrent_kernel_0.shape)\n","print(\"bias_0\", bias_0.shape)\n","print(\"output\", output.shape)\n","\n","# self.Wxh_Left (240, 60)\n","# self.Whh_Left (240, 60)\n","# self.bxh_Left (240,)\n","# self.Why_Left (5, 60)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["kernel_0 (128, 256)\n","recurrent_kernel_0 (64, 256)\n","bias_0 (256,)\n","output (64, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kF2WrhPNvtK8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612852818308,"user_tz":-540,"elapsed":227262,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"de0eebb5-3aca-4214-e8db-f0243a3d241c"},"source":["Wxh = kernel_0.T  # shape 4d*e\n","Whh = recurrent_kernel_0.T  # shape 4d\n","bxh = bias_0.T  # shape 4d \n","Why = output.T\n","\n","print(\"Wxh\", Wxh.shape)\n","print(\"Whh\", Whh.shape)\n","print(\"bxh\", bxh.shape)\n","print(\"Why\", Why.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Wxh (256, 128)\n","Whh (256, 64)\n","bxh (256,)\n","Why (2, 64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HQTIvJgpvuUB"},"source":["def lrp_linear(hin, w, b, hout, Rout, bias_nb_units, eps, bias_factor=0.0, debug=False):\n","    \"\"\"\n","    LRP for a linear layer with input dim D and output dim M.\n","    Args:\n","    - hin:            forward pass input, of shape (D,)\n","    - w:              connection weights, of shape (D, M)\n","    - b:              biases, of shape (M,)\n","    - hout:           forward pass output, of shape (M,) (unequal to np.dot(w.T,hin)+b if more than one incoming layer!)\n","    - Rout:           relevance at layer output, of shape (M,)\n","    - bias_nb_units:  total number of connected lower-layer units (onto which the bias/stabilizer contribution is redistributed for sanity check)\n","    - eps:            stabilizer (small positive number)\n","    - bias_factor:    set to 1.0 to check global relevance conservation, otherwise use 0.0 to ignore bias/stabilizer redistribution (recommended)\n","    Returns:\n","    - Rin:            relevance at layer input, of shape (D,)\n","    \"\"\"\n","    sign_out = np.where(hout[na,:]>=0, 1., -1.) # shape (1, M)\n","    \n","    numer    = (w * hin[:,na]) + ( bias_factor * (b[na,:]*1. + eps*sign_out*1.) / bias_nb_units ) # shape (D, M)\n","    # Note: here we multiply the bias_factor with both the bias b and the stabilizer eps since in fact\n","    # using the term (b[na,:]*1. + eps*sign_out*1.) / bias_nb_units in the numerator is only useful for sanity check\n","    # (in the initial paper version we were using (bias_factor*b[na,:]*1. + eps*sign_out*1.) / bias_nb_units instead)\n","    \n","    denom    = hout[na,:] + (eps*sign_out*1.)   # shape (1, M)\n","    \n","    message  = (numer/denom) * Rout[na,:]       # shape (D, M)\n","    \n","    Rin      = message.sum(axis=1)              # shape (D,)\n","    \n","    if debug:\n","        print(\"local diff: \", Rout.sum() - Rin.sum())\n","    # Note: \n","    # - local  layer   relevance conservation if bias_factor==1.0 and bias_nb_units==D (i.e. when only one incoming layer)\n","    # - global network relevance conservation if bias_factor==1.0 and bias_nb_units set accordingly to the total number of lower-layer connections \n","    # -> can be used for sanity check\n","    \n","    return Rin"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RXrMqHvrvwXk"},"source":["def LRP(target_data, target_class) :\n","    \n","    #원본 소스에서 E embedding은 전체에 대한 단어 사전이고, x는 embedding된 인풋이다.  \n","\n","    x = get_layer_output('embedding', target_data).squeeze(axis=1)\n","    e = x.shape[1]\n","\n","   ################# forword\n","    T = target_data.shape[0]\n","    d = int(256/4)  # hidden units\n","    C = Why.shape[0] # number of classes\n","    \n","    idx    = np.hstack((np.arange(0,d), np.arange(2*d,4*d))).astype(int) # indices of gates i,f,o together\n","    idx_i, idx_g, idx_f, idx_o = np.arange(0,d), np.arange(d,2*d), np.arange(2*d,3*d), np.arange(3*d,4*d) # indices of gates i,g,f,o separately\n","\n","    h  = np.zeros((T,d))\n","    c  = np.zeros((T,d))\n","\n","    gates_xh  = np.zeros((T, 4*d))  \n","    gates_hh  = np.zeros((T, 4*d)) \n","    gates_pre = np.zeros((T, 4*d))  \n","    gates     = np.zeros((T, 4*d))  \n","\n","    for t in range(T):\n","        gates_xh[t]     = np.dot(Wxh, x[t])\n","        gates_hh[t]     = np.dot(Whh, h[t-1])\n","        gates_pre[t]    = gates_xh[t] + gates_hh[t] + bxh\n","        gates[t, idx]    = 1.0/(1.0 + np.exp(- gates_pre[t,idx]))\n","        gates[t,idx_g]  = np.tanh(gates_pre[t,idx_g]) \n","        c[t]            = gates[t,idx_f]*c[t-1] + gates[t,idx_i]*gates[t,idx_g]\n","        h[t]            = gates[t,idx_o]*np.tanh(c[t])\n","\n","    s = np.dot(Why, h[t])    \n","\n","    ################# backwork\n","    dx     = np.zeros(x.shape)\n","\n","    dh          = np.zeros((T, d))\n","    dc          = np.zeros((T, d))\n","    dgates_pre  = np.zeros((T, 4*d))  # gates pre-activation\n","    dgates      = np.zeros((T, 4*d))  # gates activation\n","\n","    ds               = np.zeros((C))\n","    ds[target_class] = 1.0\n","    dy               = ds.copy()\n","\n","    #맨처음을 0으로 시작하지 않게 위한조치\n","    dh[T-1]     = np.dot(Why.T, dy)\n","\n","    for t in reversed(range(T)): \n","        dgates[t,idx_o]    = dh[t] * np.tanh(c[t])  # do[t]\n","        dc[t]             += dh[t] * gates[t,idx_o] * (1.-(np.tanh(c[t]))**2) # dc[t]\n","        dgates[t,idx_f]    = dc[t] * c[t-1]         # df[t]\n","        dc[t-1]            = dc[t] * gates[t,idx_f] # dc[t-1]\n","        dgates[t,idx_i]    = dc[t] * gates[t,idx_g] # di[t]\n","        dgates[t,idx_g]    = dc[t] * gates[t,idx_i] # dg[t]\n","        dgates_pre[t,idx]  = dgates[t,idx] * gates[t,idx] * (1.0 - gates[t,idx]) # d ifo pre[t]\n","        dgates_pre[t,idx_g]= dgates[t,idx_g] *  (1.-(gates[t,idx_g])**2) # d g pre[t]\n","        dh[t-1]            = np.dot(Whh.T, dgates_pre[t])\n","        dx[t]              = np.dot(Wxh.T, dgates_pre[t])\n","\n","    ################# LRP\n","    eps=0.001 \n","    bias_factor=0.0\n","    Rx  = np.zeros(x.shape)\n","    Rh  = np.zeros((T+1, d))\n","    Rc  = np.zeros((T+1, d))\n","    Rg  = np.zeros((T,   d)) # gate g only\n","\n","    Rout_mask            = np.zeros((C))\n","    Rout_mask[target_class] = 1.0  \n","\n","    # format reminder: lrp_linear(hin, w, b, hout, Rout, bias_nb_units, eps, bias_factor)\n","    Rh[T-1]  = lrp_linear(h[T-1], Why.T, np.zeros((C)), s, s*Rout_mask, 2*d, eps, bias_factor, debug=False)  \n","\n","    for t in reversed(range(T)):\n","        Rc[t]   += Rh[t]\n","        Rc[t-1]  = lrp_linear(gates[t,idx_f]*c[t-1], np.identity(d), np.zeros((d)), c[t], Rc[t], 2*d, eps, bias_factor, debug=False)\n","        Rg[t]    = lrp_linear(gates[t,idx_i]*gates[t,idx_g], np.identity(d), np.zeros((d)), c[t], Rc[t], 2*d, eps, bias_factor, debug=False)\n","        Rx[t]    = lrp_linear(x[t], Wxh[idx_g].T, bxh[idx_g], gates_pre[t,idx_g], Rg[t], d+e, eps, bias_factor, debug=False)\n","        Rh[t-1]  = lrp_linear(h[t-1], Whh[idx_g].T, bxh[idx_g], gates_pre[t,idx_g], Rg[t], d+e, eps, bias_factor, debug=False)    \n","\n","    return s, dx, Rx, Rh[-1].sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kgOmftpHvylz"},"source":["def index_to_word(word):\n","    full_sentence = ' '.join(index2word.get(w) for w in word)\n","    return full_sentence.split()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rpDAzjBnv1RX"},"source":["def int_to_str(target_class):\n","    if target_class == 0 :\n","        return \"긍정\"\n","    else :\n","        return \"부정\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4v9bK0Rr9vHr","colab":{"base_uri":"https://localhost:8080/","height":260},"executionInfo":{"status":"ok","timestamp":1612852819506,"user_tz":-540,"elapsed":227440,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"25e1d873-dee7-4ce1-b8fc-4e74a21e0768"},"source":["i = 0\n","\n","target_data = np.array(new_input[i])\n","target_class = np.argmax(y_train[i])\n","predictions = model.predict(new_input)\n","\n","scores, Gx, Rx, R_rest = LRP(target_data, target_class)\n","\n","R_words          = np.sum(Rx, axis=1)                       # compute word-level LRP relevances\n","R_words_SA       = (np.linalg.norm(Gx,ord=2, axis=0))**2   # compute word-level Sensitivity Analysis relevances\n","R_words_GI       = np.dot(target_data, Gx) \n","\n","\n","words = index_to_word(target_data)\n","\n","if len(words) > 0 :\n","    print(\" 예측 레이블:\", int_to_str(np.argmax(predictions[i])), \"| 실제 레이블 : \", int_to_str(target_class))\n","\n","    print(\"        LRP heatmap:\")\n","    display(HTML(html_heatmap(words, R_words)))\n","\n","    print(\"        SA heatmap:\")\n","    display(HTML(html_heatmap(words, R_words_SA)))\n","\n","    print(\"        GI heatmap:\")\n","    display(HTML(html_heatmap(words, R_words_GI)))\n","\n","    print(\"-----------------------------------------------------------\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" 예측 레이블: 긍정 | 실제 레이블 :  긍정\n","        LRP heatmap:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">PAD</span> <span style=\"background-color:#fefeff\">beauti</span> <span style=\"background-color:#fefeff\">build</span> <span style=\"background-color:#fefeff\">great</span> <span style=\"background-color:#fffefe\">locat</span> <span style=\"background-color:#fffefe\">would</span> <span style=\"background-color:#fefeff\">like</span> <span style=\"background-color:#fffefe\">resort</span> <span style=\"background-color:#fefeff\">true</span> <span style=\"background-color:#fffefe\">custom</span> <span style=\"background-color:#fefeff\">servic</span> <span style=\"background-color:#fffefe\">lack</span> <span style=\"background-color:#fffefe\">manag</span> <span style=\"background-color:#fffefe\">far</span> <span style=\"background-color:#fefeff\">profession</span> <span style=\"background-color:#fefeff\">staff</span> <span style=\"background-color:#fffefe\">look</span> <span style=\"background-color:#fefeff\">like</span> <span style=\"background-color:#fffefe\">went</span> <span style=\"background-color:#fffefe\">main</span> <span style=\"background-color:#fefeff\">loung</span> <span style=\"background-color:#fefeff\">dinner</span> <span style=\"background-color:#fefeff\">drink</span> <span style=\"background-color:#fffefe\">enough</span> <span style=\"background-color:#fffefe\">time</span> <span style=\"background-color:#fffefe\">give</span> <span style=\"background-color:#fefeff\">full</span> <span style=\"background-color:#fefeff\">staff</span> <span style=\"background-color:#fefeff\">manag</span> <span style=\"background-color:#fffefe\">allow</span> <span style=\"background-color:#fffefe\">custom</span> <span style=\"background-color:#fefeff\">walk</span> <span style=\"background-color:#fffefe\">one</span> <span style=\"background-color:#fefeff\">end</span> <span style=\"background-color:#fefeff\">hotel</span> <span style=\"background-color:#fefeff\">get</span> <span style=\"background-color:#fefeff\">enjoy</span> <span style=\"background-color:#fefeff\">loung</span> <span style=\"background-color:#fffefe\">someth</span> <span style=\"background-color:#fefeff\">miss</span> <span style=\"background-color:#fefeff\">upper</span> <span style=\"background-color:#fefeff\">manag</span> <span style=\"background-color:#fffefe\">stop</span> <span style=\"background-color:#fefeff\">two</span> <span style=\"background-color:#fffefe\">restaur</span> <span style=\"background-color:#fffefe\">ask</span> <span style=\"background-color:#fffafa\">one</span> <span style=\"background-color:#fafaff\">person</span> <span style=\"background-color:#fff0f0\">offer</span> <span style=\"background-color:#ccccff\">take</span> <span style=\"background-color:#fff8f8\">care</span> <span style=\"background-color:#dcdcff\">us</span> <span style=\"background-color:#7e7eff\">kept</span> <span style=\"background-color:#9393ff\">us</span> <span style=\"background-color:#ffcccc\">hallway</span> <span style=\"background-color:#9292ff\">set</span> <span style=\"background-color:#ff0000\">disappoint</span> \n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["        SA heatmap:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<span style=\"background-color:#ffa3a3\">PAD</span> <span style=\"background-color:#fff2f2\">PAD</span> <span style=\"background-color:#fff6f6\">PAD</span> <span style=\"background-color:#ffcece\">PAD</span> <span style=\"background-color:#ffcece\">PAD</span> <span style=\"background-color:#fffafa\">PAD</span> <span style=\"background-color:#ffe0e0\">PAD</span> <span style=\"background-color:#ffe0e0\">PAD</span> <span style=\"background-color:#fffefe\">PAD</span> <span style=\"background-color:#fff2f2\">PAD</span> <span style=\"background-color:#ffb3b3\">PAD</span> <span style=\"background-color:#ffe4e4\">PAD</span> <span style=\"background-color:#fffefe\">PAD</span> <span style=\"background-color:#ffaaaa\">PAD</span> <span style=\"background-color:#ffc2c2\">PAD</span> <span style=\"background-color:#ffc6c6\">beauti</span> <span style=\"background-color:#ffe2e2\">build</span> <span style=\"background-color:#ffe0e0\">great</span> <span style=\"background-color:#fff6f6\">locat</span> <span style=\"background-color:#ff9c9c\">would</span> <span style=\"background-color:#fffcfc\">like</span> <span style=\"background-color:#ffe0e0\">resort</span> <span style=\"background-color:#ffdcdc\">true</span> <span style=\"background-color:#ffeeee\">custom</span> <span style=\"background-color:#ffa3a3\">servic</span> <span style=\"background-color:#fffcfc\">lack</span> <span style=\"background-color:#fffafa\">manag</span> <span style=\"background-color:#ffecec\">far</span> <span style=\"background-color:#ffeaea\">profession</span> <span style=\"background-color:#fff0f0\">staff</span> <span style=\"background-color:#ff0000\">look</span> <span style=\"background-color:#ffdcdc\">like</span> <span style=\"background-color:#ffd2d2\">went</span> <span style=\"background-color:#ffc6c6\">main</span> <span style=\"background-color:#ffd6d6\">loung</span> <span style=\"background-color:#ffd8d8\">dinner</span> <span style=\"background-color:#ffc6c6\">drink</span> <span style=\"background-color:#fff2f2\">enough</span> <span style=\"background-color:#fff6f6\">time</span> <span style=\"background-color:#ffc6c6\">give</span> <span style=\"background-color:#ffeaea\">full</span> <span style=\"background-color:#ff9c9c\">staff</span> <span style=\"background-color:#ffbcbc\">manag</span> <span style=\"background-color:#ffbcbc\">allow</span> <span style=\"background-color:#fff8f8\">custom</span> <span style=\"background-color:#ffcece\">walk</span> <span style=\"background-color:#fff0f0\">one</span> <span style=\"background-color:#ffbcbc\">end</span> <span style=\"background-color:#fffcfc\">hotel</span> <span style=\"background-color:#ff7070\">get</span> <span style=\"background-color:#ffe4e4\">enjoy</span> <span style=\"background-color:#fff6f6\">loung</span> <span style=\"background-color:#ffe0e0\">someth</span> <span style=\"background-color:#fffafa\">miss</span> <span style=\"background-color:#ffb6b6\">upper</span> <span style=\"background-color:#ffd0d0\">manag</span> <span style=\"background-color:#ffeaea\">stop</span> <span style=\"background-color:#ffdede\">two</span> <span style=\"background-color:#fff8f8\">restaur</span> <span style=\"background-color:#ffe0e0\">ask</span> <span style=\"background-color:#ffdede\">one</span> <span style=\"background-color:#fff6f6\">person</span> <span style=\"background-color:#ffe6e6\">offer</span> <span style=\"background-color:#fffefe\">take</span> <span style=\"background-color:#ffeaea\">care</span> <span style=\"background-color:#ffe6e6\">us</span> <span style=\"background-color:#ffe8e8\">kept</span> <span style=\"background-color:#fffefe\">us</span> <span style=\"background-color:#fffcfc\">hallway</span> <span style=\"background-color:#fff4f4\">set</span> <span style=\"background-color:#ffdede\">disappoint</span> \n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["        GI heatmap:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<span style=\"background-color:#6666ff\">PAD</span> <span style=\"background-color:#9a9aff\">PAD</span> <span style=\"background-color:#ffa2a2\">PAD</span> <span style=\"background-color:#ff9e9e\">PAD</span> <span style=\"background-color:#6161ff\">PAD</span> <span style=\"background-color:#ffb3b3\">PAD</span> <span style=\"background-color:#ff7979\">PAD</span> <span style=\"background-color:#ff7070\">PAD</span> <span style=\"background-color:#ffe8e8\">PAD</span> <span style=\"background-color:#ff8c8c\">PAD</span> <span style=\"background-color:#6969ff\">PAD</span> <span style=\"background-color:#6e6eff\">PAD</span> <span style=\"background-color:#ffecec\">PAD</span> <span style=\"background-color:#ff2121\">PAD</span> <span style=\"background-color:#ff6161\">PAD</span> <span style=\"background-color:#ff5454\">beauti</span> <span style=\"background-color:#ff7c7c\">build</span> <span style=\"background-color:#ff6e6e\">great</span> <span style=\"background-color:#ffdada\">locat</span> <span style=\"background-color:#5c5cff\">would</span> <span style=\"background-color:#ffcccc\">like</span> <span style=\"background-color:#6969ff\">resort</span> <span style=\"background-color:#ff9898\">true</span> <span style=\"background-color:#fffefe\">custom</span> <span style=\"background-color:#ff6161\">servic</span> <span style=\"background-color:#eaeaff\">lack</span> <span style=\"background-color:#ffeeee\">manag</span> <span style=\"background-color:#ffcccc\">far</span> <span style=\"background-color:#8080ff\">profession</span> <span style=\"background-color:#ffc2c2\">staff</span> <span style=\"background-color:#ff0404\">look</span> <span style=\"background-color:#ff9090\">like</span> <span style=\"background-color:#ffaaaa\">went</span> <span style=\"background-color:#8686ff\">main</span> <span style=\"background-color:#ff5c5c\">loung</span> <span style=\"background-color:#7c7cff\">dinner</span> <span style=\"background-color:#ff6e6e\">drink</span> <span style=\"background-color:#9696ff\">enough</span> <span style=\"background-color:#ffa8a8\">time</span> <span style=\"background-color:#ff7c7c\">give</span> <span style=\"background-color:#aeaeff\">full</span> <span style=\"background-color:#3e3eff\">staff</span> <span style=\"background-color:#4949ff\">manag</span> <span style=\"background-color:#6161ff\">allow</span> <span style=\"background-color:#ffc8c8\">custom</span> <span style=\"background-color:#ff6969\">walk</span> <span style=\"background-color:#ffe0e0\">one</span> <span style=\"background-color:#6464ff\">end</span> <span style=\"background-color:#d3d3ff\">hotel</span> <span style=\"background-color:#0404ff\">get</span> <span style=\"background-color:#7878ff\">enjoy</span> <span style=\"background-color:#ffb2b2\">loung</span> <span style=\"background-color:#7c7cff\">someth</span> <span style=\"background-color:#ffb6b6\">miss</span> <span style=\"background-color:#5858ff\">upper</span> <span style=\"background-color:#ff4e4e\">manag</span> <span style=\"background-color:#7070ff\">stop</span> <span style=\"background-color:#ff7676\">two</span> <span style=\"background-color:#b2b2ff\">restaur</span> <span style=\"background-color:#8c8cff\">ask</span> <span style=\"background-color:#5858ff\">one</span> <span style=\"background-color:#b6b6ff\">person</span> <span style=\"background-color:#ffb3b3\">offer</span> <span style=\"background-color:#ffe6e6\">take</span> <span style=\"background-color:#7171ff\">care</span> <span style=\"background-color:#7474ff\">us</span> <span style=\"background-color:#aeaeff\">kept</span> <span style=\"background-color:#fff2f2\">us</span> <span style=\"background-color:#ffcece\">hallway</span> <span style=\"background-color:#ff9a9a\">set</span> <span style=\"background-color:#ff7171\">disappoint</span> \n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["-----------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T6bsGZqsouqc"},"source":["predictions = model.predict(new_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3wtZoKVrLdg"},"source":["## 특정 점수 이상의 단어들만 사전생성하는데 사용된다.\n","## cut-off 설정 가능\n","\n","def make_dict(x_, y_, thres : float, break_ : int):\n","  sent_dict = {}\n","  predictions = model.predict(x_)\n","  j = 0\n","  for i in range(len(x_)):\n","    \n","    if i % 100 == 0:\n","      print( i,'/',len(x_))\n","\n","    if max(predictions[i]) > thres : \n","      \n","      target_data = np.array(x_[i])\n","      target_class = np.argmax(y_[i])\n","    \n","      scores, Gx, Rx, R_rest = LRP(target_data, target_class)\n","\n","      R_words          = np.sum(Rx, axis=1)                       # compute word-level LRP relevances\n","      # R_words_SA       = (np.linalg.norm(Gx,ord=2, axis=0))**2   # compute word-level Sensitivity Analysis relevances\n","      # R_words_GI       = np.dot(target_data, Gx) \n","      words = index_to_word(target_data)\n","      if target_class == 1:\n","        tmp = {k:v for k,v in zip(words,R_words)}\n","      else:\n","        tmp = {k:-v for k,v in zip(words,R_words)}\n","      \n","      for k,v in tmp.items():\n","        if k in sent_dict:\n","          if abs(sent_dict[k]) < abs(v):\n","            sent_dict[k] = v\n","          else :\n","            None\n","        else :\n","          sent_dict[k] = v\n","      j+=1\n","      \n","    if j == break_:\n","        break\n","      \n","\n","  return sent_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g_UlFkKwy8Ia"},"source":["sent_dict = make_dict(X_train, y_train, 0.8, 700)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvL5Adg1HVyC"},"source":["sorted(sent_dict.items(),key=operator.itemgetter(1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sRuhsEYtIxsq"},"source":["sorted(sent_dict.items(),key=operator.itemgetter(1), reverse= True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5NArIdt74wUl"},"source":["sent_dict.pop('PAD')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ueUaxoJi8bID"},"source":["## 부호를 이용해서 긍부정 단어 구분\n","\n","def seperate(sent_dict):\n","  pos_ = {}\n","  neg_ = {}\n","\n","  for k,v in sent_dict.items():\n","    if v < 0:\n","      pos_[k] = v\n","    else:\n","      neg_[k] = v\n","\n","  return pos_, neg_\n","\n","pos_, neg_ = seperate(sent_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GmdzVJOq7YFZ"},"source":["test_ = preprocessing(test_X[:1000])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aW9LjP7W-0Yi"},"source":["## 사전 정규화 진행\r\n","\r\n","def dict_normalize(score_dict):\r\n","  dict_ = score_dict.copy()\r\n","  key = list(dict_.keys())\r\n","  value = np.array(list(dict_.values()))\r\n","  value /= np.max(abs(value))\r\n","  normalize_dict = {k:v for k, v in zip(key, value)} \r\n","  return normalize_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KjC_H9DG4Mff"},"source":["## 기준점수가 0이 아닌경우가 있다...\n","## test_set labeling 과정 긍/부정 함수를 정규화 후 라벨링 진행\n","\n","def semi_labeling(tkns):\n","\n","  pos_norm = dict_normalize(pos_)\n","  neg_norm = dict_normalize(neg_)\n","\n","  test_label = []\n","  for tokens in tkns:\n","    p = 0\n","    n = 0\n","    for t in tokens:\n","      if t in pos_norm:\n","        p+=pos_norm[t]\n","      elif t in neg_norm:\n","        n+=neg_norm[t]\n","      else:\n","        None\n","    \n","    if p+n <= -5:\n","      test_label.append(0)\n","    else:\n","      test_label.append(1)\n","  \n","  return test_label\n","\n","test_label = semi_labeling(test_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x3inr5wpwH4J"},"source":["## Delete 0 for LRP\n","\n","def make_input(tkns, train_label):\n","  num_recs = len(tkns)\n","\n","  new_X = np.empty((num_recs, ), dtype=list)     \n","  i = 0\n","\n","  for sentence, label in zip(corpus(tkns), train_label):\n","      words = nltk.word_tokenize(sentence)  \n","      seqs = []\n","      for word in words:                 \n","          if word in word2index:         \n","              seqs.append(word2index[word])       \n","          else:\n","              None   \n","\n","      new_X[i] = seqs              \n","    \n","      i += 1\n","\n","  return new_X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7mdjO0aAatYx"},"source":["## 0.1 이상의 점수를 가진 단어중 본 사전의 단어보다 절대값이 큰 경우에 사전 업데이트에 반영\r\n","\r\n","def update_dict(p_, n_):\r\n","\r\n","  for k, v in p_.items():\r\n","\r\n","    if v > 0.1:\r\n","      if k in pos_:\r\n","        if pos_[k] < v:\r\n","          None\r\n","        else :\r\n","          pos_[k] = v\r\n","  \r\n","  for k, v in n_.items():\r\n","    if v > 0.1:\r\n","      if k in neg_:\r\n","        if neg_[k] < v:\r\n","          neg_[k] = v\r\n","        else:\r\n","          None\r\n","\r\n","  return pos_, neg_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xA3cH_zZ7vzk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612842717549,"user_tz":-540,"elapsed":93191,"user":{"displayName":"황호현","photoUrl":"","userId":"08388564785236291532"}},"outputId":"57bedb80-eb07-475e-c573-f750427d4815"},"source":["## 실제값과 예측값 정확도 비교\n","\n","from collections import Counter\n","\n","def acc_count(tlabel, test_label):\n","  label_count = Counter(np.array(tlabel[:1000]) - np.array(test_label))\n","  return (Counter(label_count)[0]/len(test_label))\n","\n","acc_count(test_Y, test_label)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.823"]},"metadata":{"tags":[]},"execution_count":146}]},{"cell_type":"code","metadata":{"id":"qJz4wSdzXBsH"},"source":["## 뒤에서 부터 1000개 validation data 생성\r\n","\r\n","val_X = preprocessing(test_X[-1000:])\r\n","val_y = test_Y[-1000:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CiPQLE7a7x_H"},"source":["p = len(pos_)\n","n = len(neg_)\n","t_acc = []\n","v_acc = []\n","\n","for i in range(1,len(test_X)//1000 + 1):\n","  test_cnts = test_X[1000*i:1000*(i+1)]\n","  test_tokens = preprocessing(test_cnts)\n","  test_corp = corpus(test_tokens)\n","  test_label = semi_labeling(test_tokens)\n","  label_ = test_Y[1000*i:1000*(i+1)]\n","  label_ = keras.utils.to_categorical(label_, num_classes)\n","\n","  before = make_input(test_tokens, label_)\n","  n_X = sequence.pad_sequences(before, maxlen=max_len)\n","  # 새로 추가된 1000개 데이터로 사전 생성\n","  sent_dict = make_dict(n_X, label_, 0.95, 100)\n","  p_, n_ = seperate(sent_dict) ## 긍부정 분류\n","  # 사전 업데이트\n","  pos_, neg_ = update_dict(p_, n_)\n","\n","  print(i,\"/\",len(test_X)//1000)\n","  \n","  acc = acc_count(test_Y[1000*i:1000*(i+1)], test_label)\n","  print(\"test 결과 : \", acc)\n","  t_acc.append(acc)\n","\n","  prediction = semi_labeling(val_X)\n","  print(\"validation 결과 :\", acc_count(val_y, prediction))\n","  v_acc.append(acc_count(val_y, prediction))\n","  #print(len(pos_)-p,'개 긍정단어 추가', len(neg_)-n,'개 부정단어 추가')\n","\n","  if i == 35 :\n","    break\n","  p = len(pos_)\n","  n = len(neg_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ubD5t9p8-swo"},"source":["v_acc"],"execution_count":null,"outputs":[]}]}